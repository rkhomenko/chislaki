\documentclass[a4paper,12pt]{article}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{amsmath}
\usepackage{geometry}

\geometry{left=1cm}
\geometry{right=1cm}
\geometry{top=1cm}
\geometry{bottom=1.5cm}

\usepackage[normalem]{ulem}
\usepackage{hyperref}
\usepackage{listings}


\begin{document}

\begin{titlepage}
\begin{center}
    {Московский авиационный институт} \\
    {(национальный исследовательский университет)} \\
    {Кафедра 806}

\vspace{8cm}
\large{
    {Лабораторная работа №1} \\
    {по курсу <<Численные методы>>} \\
    {Тема: <<Численные методы линейной алгебры>>}
}
\end{center}

\vspace{6cm}
\begin{flushright}
\begin{minipage}{0.4\textwidth}
    \begin{flushleft}
        {Выполнил: студент группы 8О-308} \\
        {Хоменко Роман Дмитриевич} \\
        \vspace{0.5cm}
        {Перподаватель:} \\
        {к.ф.-м.н., доцент кафедры 806} \\
        {Иванов Игорь Эдуардович} \\
        \vspace{0.5cm}
        Оценка:
    \end{flushleft}
\end{minipage}
\end{flushright}

\vfill
\begin{center}
    {Москва, 2018}
\end{center}

\end{titlepage}

\section{Решение систем линейных алгебраических уравнений}

\subsection{Метод Гаусса}
\subsubsection{Задание}
Реализовать алгоритм LU-разложения матриц (с выбором главного элемента)
в виде программы. Используя разработанное программное обеспечение,
решить систему линейных алгебраических уравнений (СЛАУ). Для матрицы СЛАУ вычислить
определитель и обратную матрицу.

\subsubsection{LU-разложение}
Компьютерная реализация метода Гаусса часто осуществляется
через LU-разложение матриц.

LU-разложение  представляет собой разложение матрицы $A$ в
произведение нижней и верхней треугольных матриц
$$
A = LU,
$$
где $L$ - нижняя треугольная матрица, $U$ - верхняя треугольная.

LU-разложение может быть построенно с помощью метода Гаусса.
На $k$-ом шаге метода Гаусса осуществляется обнуление
поддиагональных элементов $k$-го столбца матрицы $A^{(k - 1)}$.
Для этого используется следующая операция:
$$a^{(k)}_{ij} = a^{(k - 1)_{ij}} - \mu_i^{(k)} a_{kj}^{(k - 1)},
\ \mu_i^{(k)} = \frac{a_{ik}^{(k - 1)}}{a_{kk}^{(k - 1)}},
\ i = \overline{k + 1, n},\ j = \overline{k, n}.$$

В терминах матричных операций такая операция эквивалентна
умножению $A^{(k)} = M_k A^{(k - 1)}$. Матрица $M_k$ имеет вид
$$
\begin{pmatrix}
    1 & 0 & 0 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 & 0 & 0 \\
    0 & 0 & 1 & 0 & 0 & 0 \\
    0 & 0 & -\mu_{k+1}^{(k)} & 1 & 0 & 0 \\
    \vdots & \vdots & \vdots & \vdots & \vdots \\
    0 & 0 & -\mu_{n}^{(k)} & 0 & 0 & 1 \\
\end{pmatrix}
$$

Выражение для обратной операции запишется в виде
$A^{(k-1)} = M^{-1}_k A^{(k)}$, где
$$
M_k^{-1} =
\begin{pmatrix}
    1 & 0 & 0 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 & 0 & 0 \\
    0 & 0 & 1 & 0 & 0 & 0 \\
    0 & 0 & \mu_{k+1}^{(k)} & 1 & 0 & 0 \\
    \vdots & \vdots & \vdots & \vdots & \vdots \\
    0 & 0 & \mu_{n}^{(k)} & 0 & 0 & 1 \\
\end{pmatrix}
$$

В результате прямого хода метода Гаусса получим $A^{(n - 1)} = U$,
$$
A = A^{(0)} = M_1^{-1} A^{(1)} = M_1^{-1} M_2^{-1} A^{(2)}
= M_1^{-1} M_2^{-1} \ldots M_{n - 1}^{-1}A^{(n - 1)},
$$
где $A^{(n - 1)} = U$ - верхняя треугольная матрица, а
$L = M_1^{-1} M_2^{-1} \ldots M_{n - 1}^{-1}$ - нижняя треугольная
матрица, имеющая вид
$$
L =
\begin{pmatrix}
    1 & 0 & 0 & 0 & \ldots & 0 & 0\\
    \mu_{2}^{(1)} & 1 & 0 & 0 & \ldots & 0 & 0\\
    \mu_{3}^{(1)} & \mu_{3}^{(2)} & 1 & 0 & \ldots & 0 & 0\\
    \vdots & \vdots & \mu_{k+1}^{(k)} & 1 & \ldots & 0 & 0 \\
    \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
    \mu_{n}^{(1)} & \mu_{n}^{(2)}  & \mu_{n}^{(k)} &
            \mu_{n}^{(k + 1)} & \ldots &  \mu_{n}^{(n - 1)} & 1\\
\end{pmatrix}
$$

\subsubsection{Вычисление определителя}
Так как $A = LU$, где $L$ - нижняя треугольная матрица
с единичными элементами на главной диагонали,
$U$ - верхняя треугольная матрица и $\det{AB} =\det{A}\det{B}$, то
$$
\det{A} = \prod_{i = 1}^{n} u_{ii}.
$$

\subsubsection{Решение СЛАУ}
LU-разложение можно эффективно использовать при решении
СЛАУ вида $Ax = b$. Подставим $A = LU$:
$$
LUx = b,\ Ux = L^{-1}b,
$$
т.е. процесс решения СЛАУ сводится к двум простым этапам.

\textit{Этап 1}. Решаем СЛАУ $Lz = b$. Т.к. $L$ - нижняя треугольная,
то решение можно записать в явном виде:
$$
z_1 = b_1,\ z_i = b_i - \sum_{j = 1}^{i - 1}l_{ij},\ i = \overline{2, n}.
$$

\textit{Этап 2}. Решаем СЛАУ $Ux = z$ с верхней треугольной
матрицей. Записываем решение в явном виде:
$$
x_n = \frac{z_n}{u_{nn}},\ x_i = \frac{1}{u_{nn}}(z_i -
    \sum_{j = i + 1}^{n} u_{ij} x_j,\ i = \overline{n - 1, 1}.
$$

\subsubsection{Вычисление обратной матрицы}
Находить обратную матрицу будем следующим образом.
Из $AA^{-1} = E$ становится очевидно, что можно искать
матрицу $A^{-1}$ по столбцам:
$$
A x_i = e_i,\ e_i = (0\ \ldots \underset{(i)}{1}\ \ldots\ 0)^{T}
$$
В результате решения $n$ СЛАУ, получаем матрицу $A^{-1}$:
$$
A^{-1} = (x_1\ x_2\ \ldots\ x_n).
$$

\subsubsection{Лог программы}
\begin{verbatim}
******************************** A, b ********************************
A:
              9              -5              -6               3
              1              -7               1               0
              3              -4               9               0
              6              -1               9               8
b:
             -8
             38
             47
             -8
************************** LU decomposition **************************
L:
              1               0               0               0
     0.11111111               1               0               0
     0.66666667     -0.36206897               1               0
     0.33333333      0.36206897      0.76425856               1
U:
              9              -5              -6               3
              0      -6.4444444       1.6666667     -0.33333333
              0               0       13.603448       5.8793103
              0               0               0      -5.3726236
P:
              1               0               0               0
              0               1               0               0
              0               0               0               1
              0               0               1               0
Checking: A = P^(T)LU
              9              -5              -6               3
              1              -7               1               0
              3              -4               9               0
              6              -1               9               8
************************* Solve linear system *************************
x:
  3.8549411e-19
             -5
              3
             -5
Checking: A * x
             -8
             38
             47
             -8
***************************** Determinant *****************************
-4239
****************************** Iversion ******************************
inverse(A):
     0.11134702     -0.14932767      0.13257844    -0.041755131
    0.011323425     -0.16772824     0.030431706   -0.0042462845
   -0.032083038    -0.024769993     0.080443501     0.012031139
   -0.046001415      0.11889597      -0.1861288      0.14225053
Checking: A * inverse(A)
              1   2.7105054e-20               0               0
              0               1               0  -8.4703295e-22
              0   2.7105054e-20               1  -6.7762636e-21
  2.7105054e-20               0               0               1
\end{verbatim}

\newpage

\subsection{Метод прогонки}
\subsubsection{Задание}
Реализовать метод прогонки в виде программы,
задавая в качестве входных данных ненулевые элементы матрицы
системы и вектор правых частей. Используя разработанное
программное обеспечение, решить СЛАУ с трехдиагональной матрицей.

\subsubsection{Метод прогонки}
Если матрица системы - трехдиагональная, то можно сильно улучшить метод Гаусса.
Будем рассматривать матрицу системы $Ax = d$:
$$
A =
\begin{pmatrix}
    b_1 & c_1 & 0 & 0 & \ldots & 0 & 0\\
    a_2 & b_2 & c_2 & 0 & \ldots & 0 & 0\\
    0 & a_3 & b_3 & c_3 & \ldots & 0 & 0\\

    \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
    0 & 0 & 0 & 0 & a_{n - 1} & b_{n - 1} & c_{n - 1} \\
    0 & 0 & 0 & 0 & \ldots &  a_{n} & b_{n} \\
\end{pmatrix}
$$

Решение такой системы будем искать в виде
$$
x_i = P_i x_{i + 1} + Q_i,\ i = \overline{1, n}.
$$
Легко найти $P_i$ и $Q_i$:
\begin{multline}
\\
P_1 = \frac{-c_1}{b_1},\ Q_1 = \frac{d_1}{b_1} \\
P_i = \frac{-c_i}{b_i + a_i P_{i - 1}},
\ Q_i = \frac{d_i - a_iQ_{i - 1}}{b_i + a_i P_{i - 1}},\ i = \overline{2, n - 1} \\
P_n = 0,\ Q_n = \frac{d_n - a_nQ_{n - 1}}{b_n + a_n P_{n - 1}} \\
\end{multline}
Прямой ход метода прогонки завершен.

Обратный ход метода прогонки:
$$
\left\{
    \begin{array}{l}
        x_n = Q_n, \\
        x_{n - 1} = P_{n - 1}x_n + Q_{n - 1}, \\
        x_{n - 2} = P_{n - 2}x_{n - 1} + Q_{n - 2}, \\
        \vdots \\
        x_1 = P_1 x_2 + Q_1
    \end{array}
    \right.
$$

\subsubsection{Лог программы}
\begin{verbatim}
******************************** A, b ********************************
A:
             13              -5               0               0               0
             -4               9              -5               0               0
              0              -1             -12              -6               0
              0               0               6              20              -5
              0               0               0               4               5
d:
            -66
            -47
            -43
            -74
             14
************************** Thomas algorithm **************************
x:
             -7
             -5
              6
             -4
              6
Checking: Ax = d
            -66
            -47
            -43
            -74
             14
\end{verbatim}
\newpage


\subsection{Метод простых итераций. Метод Гаусса-Зейделя}
\subsubsection{Задание}
Реализовать метод простых итераций и метод Зейделя в виде программ,
задавая в качестве входных данных матрицу системы, вектор правых
частей и точность вычислений. Используя разработанное программное
обеспечение, решить СЛАУ. Проанализировать количество итераций,
необходимое для достижения заданной точности.

\subsubsection{Метод простых итераций}
Метод простых итераций является первым рассмотренным
итеративным методом, т.е. для вычисления значения на $k$-ой
итерации используется значение, вычисленное на $k - 1$-ой
итерации.

Рассмотрим СЛАУ $Ax = b$. Для метода простых итераций ее
необходимо привести к эквивалентному виду
$$
x = \beta + \alpha x,
$$
где $\alpha$ - матрица размера $n \times n$, a $\beta$ - вектор.

Такое представление не единственно. Определим $\alpha$ и $\beta$:
$$
\beta_i = \frac{b_i}{a_{ii}},\ \alpha_{ij} = -\frac{a_{ij}}{a_{ii}},
\ i, j = \overline{1, n}, i \not = j,\ \alpha_{ij} = 0, i = j,
i = \overline{1, n}.
$$
Такое преобразование называют преобразованием Якоби.

В качестве нулевого приближения возьмем $x^{(0)} = \beta$.
Метод простых итераций будет иметь вид:
$$
\left\{
    \begin{array}{l}
        x^{(0)} = \beta \\
        x^{(1)} = \beta + \alpha x^{(0)} \\
        x^{(2)} = \beta + \alpha x^{(1)} \\
        \vdots \\
        x^{(k)} = \beta + \alpha x^{(k - 1)}.
    \end{array}
    \right.
$$

\textit{Достаточное условие сходимости метода простых итераций:}
метод простых итераций сходится к единственному
решению при любом начальном приближении $x^{(0)}$,
если какая-либо норма матрицы $\alpha$ эквивалентной системы
меньше $1$, т.е. $|| \alpha || < 1$.

Если используется преобразование Якоби, то достаточным
условием сходимости является диагональное преобладание
матрицы $A$, т.е.
$$
|a_{ii}| > \sum_{j = 1,\ i \not = j}^{n} |a_{ij}|\ \forall i.
$$

\textit{Условие окончания итерационного процесса:}
$$
\frac{||\alpha||}{1 - ||\alpha||} || x^{(k)} - x^{(k - 1)} ||
= \epsilon^{(k)}.
$$
При $||\alpha|| = 1$ в качестве критерия окончания
итерационного процесса следует использовать неравенство
$$
|| x^{(k)} - x^{(k - 1)} || < \epsilon.
$$

\subsubsection{Метод Гаусса-Зейделя}
Метод Гаусса-Зейделя является улучшением метода простых итераций.
Вектор $x^({k)}$ считается покоординатно, и для вычисления
следующей координаты используются значения, уже вычисленные
на данной итерации. Это позволяет значительно ускорить
сходимость итерационного процесса.

Представляем систему $Ax = b$ в эквивалентном виде
$x = \beta + \alpha x$ и примем $x^{(0)} = \beta$.
Тогда метод Гаусса-Зейделя для известного
вектора $x^{(k)}$ на $k$-ой итерации имеет вид:
$$
\left\{
    \begin{array}{l}
        x_1^{(k + 1)} = \beta_1 + \alpha_{11} x_1^{(k)} +
            \alpha_{12} x_2^{(k)} + \ldots + \alpha_{1n} x_n^{(k)} \\
        x_2^{(k + 1)} = \beta_2 + \alpha_{21} x_1^{(k + 1)} +
            \alpha_{22} x_2^{(k)} + \ldots + \alpha_{2n} x_n^{(k)} \\
        x_3^{(k + 1)} = \beta_3 + \alpha_{31} x_1^{(k + 1)} +
            \alpha_{32} x_2^{(k + 1)} + \ldots + \alpha_{3n} x_n^{(k)} \\
        \vdots \\
        x_n^{(k + 1)} = \beta_n + \alpha_{n1} x_1^{(k + 1)} +
            \alpha_{n2} x_2^{(k + 1)} + \ldots +
            \alpha_{n n-1} x_{n - 1}^{(k + 1)}  +
            \alpha_{nn} x_n^{(k)} \\
    \end{array}
    \right.
$$

Из данной системы видно, что $x^{(k + 1)} = \beta + B x^{(k + 1)}
+ Cx^{(k)}$, где $B$ - нижняя треугольная матрица
с нулевыми диагональными элементами, а $C$ - верхняя
треугольная с ненулевыми диагональными элементами,
$\alpha = B + C$. Откуда
\begin{multline}
\\
(E - B)x^{(k + 1)} = Cx^{(k)} + \beta \\
x^{(k + 1)} = (E - B)^{-1}Cx^{(k)} + (E - B)^{-1}\beta.
\end{multline}

Легко видеть, что метод Гаусса-Зейделя является методом простых
итераций с матрицей правых частей $(E - B)^{-1}C$ и вектором
правых частей $(E - B)^{-1}\beta$.

\textit{Критерий окончания итерационного процесса:}
$$
\epsilon^{(k)} = \frac{||C||}{1 - ||\alpha||} ||x^{(k)} - x^{(k - 1)}||.
$$

В отличие от метода простых итераций, метод Гаусса-Зейделя
может сходится и при $||\alpha|| < 1$. В этом случае
$\epsilon^{(k)} = ||x^{(k)} - x^{(k - 1)}||$.

\subsubsection{Лог программы}
\begin{verbatim}
||x_k - x_k-1|| = 0.0011889865
x_k:
      1.0000869
      2.0000392
      2.9999514
     -1.9999366
||x_k - x_k-1|| = 0.00033117259
x_k:
     0.99975576
      1.9998193
      3.0002267
     -2.0001992
Iteration count: 17
Checking Ax = b:
     -25.992383
     -54.995383
     -58.008534
     -24.002626
b:
            -26
            -55
            -58
            -24
\end{verbatim}

\begin{verbatim}
||x_k - x_k-1|| = 0.0041769369
x_k:
     0.99989515
      2.0000426
      2.9999822
     -2.0000078
||x_k - x_k-1|| = 0.00035229905
x_k:
      1.0002475
      2.0001305
      3.0000488
     -2.0000033
Iteration count: 10
Checking Ax = b:
     -26.006367
     -55.004307
     -57.998608
            -24
b:
            -26
            -55
            -58
            -24
\end{verbatim}

\newpage

\section{Нахождение собственных значений и собственных векторов}
\subsection{Метод вращений Якоби}
\subsubsection{Задание}
Реализовать метод вращений в виде программы, задавая в качестве входных
данных матрицу и точность вычислений. Используя разработанное программное
обеспечение, найти собственные значения и собственные векторы
симметрических матриц. Проанализировать зависимость погрешности
вычислений от числа итераций.

\subsubsection{Метод вращений Якоби}
Будем решать задачу нахождения собственных значений и собственных
векторов матрицы $A$, а именно
$$
Ax = \lambda x.
$$

Рассматриваемый метод вращений работает только для симметрических
матриц ($A = A^{T}$) и позволяет найти собственные значения и
собственные векторы такой матрицы. С помощью итерационных
процедур ищется преобразование подобия $\Lambda = U^{-1} A U$.
Для симметрических матриц матрица преобразования подобия
является ортогональной ($U^{-1} = U^{T}$), Поэтому
$\Lambda = U^{T} A U$, где $\Lambda$ - диагональная матрица с
собственными значениями на главной диагонали
$$
\Lambda =
\begin{pmatrix}
    \lambda_1 & \ldots & 0 \\
    \ldots & \ddots & \ldots \\
    0 & \ldots & \lambda_n
\end{pmatrix}
$$

Пусть дана симметрическая матрица $A$. Требуется с точностью
$\epsilon$ вычислить все её собственные значения и собственные
векторы. Алгоритм метода вращений следующий:

Пусть известна матрица $A^{(k)}$ на $k$-ой итерации, при этом
$k = 0$ $A^{(0)} = A$.
\begin{enumerate}
    \item Выбирается максимальный по модулю недиагональный
    элемент $a_{ij}^{(k)}$ матрицы $A^{(k)}$.
    \item Ставится задача найти ортогональную матрицу $U^{(k)}$,
    чтобы в результате преобразования подобия
    $A^{(k + 1) = U^{(k) T} A^{(k)} U^{(k)}}$
    произошло обнуление элемента $a_{lp}^{(k + 1)}$
    матрицы $A^{(k + 1)}$. В качестве ортогональной выбирается
    марица вращения на угол $\phi$, получаемая из единичной
    заменой следующих элементов:
    \begin{multline}
    \\
    u^{(k)}_{ll} = \cos{\phi^{(k)}} \\
    u^{(k)}_{pl} = \sin{\phi^{(k)}} \\
    u^{(k)}_{lp} = -\sin{\phi^{(k)}} \\
    u^{(k)}_{pp} = \cos{\phi^{(k)}} \\
    \end{multline}
    Угол вращения определяется как
    $$
    \phi^{(k)} = \frac{1}{2}\arctg{\frac{2a_{lp}^{(k)}}{a_{ll}^{(k)} - a_{pp}^{(k)}}},
    $$
    или $\phi^{(k)} = \frac{\pi}{4}$, если $a_{ll}^{(k)} = a_{pp}^{(k)}$.

    \item Строится матрица $A^{(k + 1)} = U^{(k)T} A^{(k)} U^{(k)}$, 
        в которой $a_{lp}^{(k + 1)} \approx 0$.
\end{enumerate}

В качестве критерия окончания итерационного процесса выступает условие
малости внедиагональных элементов:
$$
\text{off}(A^{(k + 1)}) = (\sum_{i,j;\ i < j} (a_{ij}^{(k + 1)})^2)^{\frac{1}{2}}
$$
Пока $\text{off}(A^{(k + 1)}) > \epsilon$ итерационный процесс
$$
A^{(k + 1)} = U^{(k)T} A^{(k)} U^{(k)} = U^{(k)T} U^{(k - 1)T} \ldots\ U^{(0)T} A^{(0)}
U^{(0)} \ldots\ U^{(k - 1)} U^{(k)}
$$
продолжается. После окончания итерационного процесса искомые
собственные значения могут быть найдены как
$$
\lambda_1 \approx a_{11}^{(k + 1)}, \ldots,\ \lambda_n \approx a_{nn}^{(k + 1)}.
$$

Собственные векторы могут быть найдены в столбцах матрицы
$U = U^{(0)} U^{(1)} \ldots U^{(k)}$, т.е.
$$
x_1 = (u_{11}\ u_{21} \ldots\ u_{n1})^{T},\ \ldots,\ x_n = (u_{n1}\ u_{n2} \ldots\ u_{nn})^{T}.
$$

\subsubsection{Лог программы}
\begin{verbatim}
A:
       7.226812   2.1684043e-19       3.1473388 
              0       -6.226812     -0.30701569 
      3.1473388     -0.30701569               2 
***********************************
A:
      8.7043267     -0.13046708   2.1684043e-19 
    -0.13046708       -6.226812     -0.27791541 
   1.490778e-19     -0.27791541      0.52248529 
***********************************
A:
      8.7043267     -0.13035699    0.0053586315 
    -0.13035699      -6.2382364   1.0842022e-19 
   0.0053586315               0      0.53390966 
***********************************
A:
      8.7054639   2.0328791e-19    0.0053584276 
              0      -6.2393735   4.6742673e-05 
   0.0053584276   4.6742673e-05      0.53390966 
***********************************
A:
      8.7054674   3.0651093e-08               0 
  3.0651093e-08      -6.2393735   4.6742663e-05 
 -5.9133488e-20   4.6742663e-05      0.53390615 
***********************************
A:
      8.7054674   3.0651093e-08   2.1152437e-13 
  3.0651093e-08      -6.2393735  -3.3087225e-24 
  2.1152431e-13  -1.0907307e-19      0.53390615 
***********************************
l_1 = 8.7054674
x_1:
     0.83032442 
     0.36022501 
       0.425205 
Ax
      7.2283622 
      3.1359271 
      3.7016083 
lx
      7.2283622 
      3.1359271 
      3.7016083 
***********************************
l_2 = -6.2393735
x_2:
    -0.41520774 
     0.90880771 
    0.040878778 
Ax
      2.5906362 
     -5.6703908 
    -0.25505795 
lx
      2.5906362 
     -5.6703908 
    -0.25505796 
***********************************
l_3 = 0.53390615
x_3:
    -0.37170403 
    -0.21049106 
     0.90417345 
Ax
    -0.19845507 
    -0.11238247 
     0.48274376 
lx
    -0.19845507 
    -0.11238247 
     0.48274376 
***********************************
\end{verbatim}

\newpage

\subsection{QR-алгоритм}
\subsubsection{Задание}
Реализовать алгоритм QR – разложения матриц в виде программы.
На его основе разработать программу, реализующую QR – алгоритм решения
полной проблемы собственных значений произвольных матриц, задавая в
качестве входных данных матрицу и точность вычислений. С использованием
разработанного программного обеспечения найти собственные значения матрицы.

\subsubsection{QR-разложение}
Будем искать разложение матрицы $A$ в виде
$A = QR$, где $Q$ -- ортогональная матрица ($Q^{-1} = Q^{T}$), а
$R$ - верхняя треугольная. Такое разложение существует для любой
квадратной матрицы. Одним из подходов к построению данного
изложение является использования преобразования Хаусхолдера,
позволяющего обнулить группу поддиагональных элементов матрицы.

Преобразование Хаусхолдера осуществляется с использованием
матрицы Хаусхолдера:
$$
H = E - \frac{2}{\nu^{T}\nu} \nu\nu^{T},
$$

Лекго видеть, что любая матрица такого вида является симметрической
и ортогональной.

Для обнуления группы поддиагональных элементов в $k$-ом столбце матрицы следует
использовать столбец $\nu$ вида:
$$
\begin{array}{l}
    \nu^{(k)}_i = 0, i = \overline{1, k - 1}, \\
    \nu^{(k)}_k = a_{kk}^{k} + sign(a_{kk}^{k})
        (\sum_{j = k}^{n}(a^{k}_{jk})^2)^{\frac{1}{2}}, \\
    \nu^{(k)}_i = a_{ik}^{(k)}, i = \overline{k + 1, n}.
\end{array}
$$

Повторяя процесс $n - 1$ раз получим, получим искомое разложение
$A = QR$, где 
$$
Q = (H_{n - 1}H_{n -2} \ldots\ H_{0})^T =
H_1 H_2 \ldots\ H_{n - 1},\ R = A_{n - 1}.
$$

\subsubsection{QR-алгоритм}
Для нахождения собственных значений строится следующий итерационный
процесс:
$$
\begin{array}{l}
    A^{(0)} = A, \\
    A^{(0)} = Q^{(0)} R^{(0)}, -- разложение \\
    A^{(1)} = R^{(0)} Q^{(0)}, -- перемножение \\
    \vdots \\
    A^{(k)} = Q^{(k)} R^{(k)}, -- разложение \\
    A^{(k + 1)} = R^{(k)} Q^{(k)} -- перемножение
\end{array}
$$

\textit{Критерий сходимости итерационного процесса:}
При отсутствии у матрицы кратных собственных
значений последовательность $A^{(k)}$ сходится к
верхней треугольной матрицы (если все собственные значения вещественны),
или к верхней квазитреугольной (если есть комплексные собственные
значения).

Для столбцов с вещественным собственным значением оценкой
погрешности является стремлением к нулю поддиагональных
элементов.

Каждой паре комплексно-сопряженных собственных значений соответствует
блок $2 \times 2$. Комплексные собственные значения находятся в ходе
решения квадратного уравнения:
$$
(a^{(k)}_{jj} - \lambda^{(k)})(a^{(k)}_{j + 1 j + 1} - \lambda^{(k)}) = a^{(k)}_{j j+1} a^{(k)}_{j + 1 j}.
$$
Значения в таких блоках от итерации к итерации меняются хаотически, поэтому
критерием окончания итерационного процесса является
$$
|\lambda^{(k)} - \lambda^{(k - 1)}| < \epsilon.
$$

\subsubsection{Лог программы}
\begin{verbatim}
A:
     -4.8429728        8.292358      -2.2626041 
     -4.1400612      -5.9885967       8.0196991 
 -1.6558761e-06  -5.9538536e-07       4.8315696 
35
A:
     -3.2758066       5.9733049      -3.4912878 
     -6.4591128      -7.5557612      -7.5661033 
 -1.2556898e-06  -5.9405807e-07       4.8315677 
36
**********************************
(-5.4157846,-5.8311873)
(0,0)
7.9582327
**********************************
A:
     -6.8761062        4.633184       8.3270513 
     -7.7992338      -3.9554629      0.30852867 
 -8.3770959e-07   5.8488302e-08       4.8315692 
37
**********************************
(-5.4157843,-5.8311877)
(-5.4157846,-5.8311873)
4.4073186e-07
**********************************
A:
     -6.8033368       7.8633897      -5.7382779 
     -4.5690285      -4.0282318       6.0421145 
 -3.8927001e-07   4.0193489e-08       4.8315686 
38
l_0 = (-5.4157843,-5.8311877)
l_1 = (-5.4157843,5.8311877)
l_2 = (4.8315686,0)
\end{verbatim}

\newpage

\section{Исходный код}
Исходный код доступен по ссылке
\url{https://github.com/rkhomenko/chislaki}.

\lstinputlisting[language=C++]{../../include/chislaki/linalg/matrix.hpp}
\lstinputlisting[language=C++]{../../include/chislaki/linalg/decompositions.hpp}
\lstinputlisting[language=C++]{../../include/chislaki/linalg/utility.hpp}
\lstinputlisting[language=C++]{../../tests/chislaki-lab01-1.cpp}
\lstinputlisting[language=C++]{../../tests/chislaki-lab01-2.cpp}
\lstinputlisting[language=C++]{../../tests/chislaki-lab01-3.cpp}
\lstinputlisting[language=C++]{../../tests/chislaki-lab01-4.cpp}
\lstinputlisting[language=C++]{../../tests/chislaki-lab01-5.cpp}

\end{document}
